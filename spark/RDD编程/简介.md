## RDD概念
RDD(Resilient Distribute DateSet):弹性分布式数据集
RDD其实就是分布式的元素集合。在Spark中，对数据的所有操作不外乎创建RDD、转化已有RDD以及调用RDD操作进行求职。而在这一切背后，Spark会自动将RDD中的数据分发到集群上，并将操作并行化执行。
## 创建RDD
Spark中的RDD就是一个不可变的分布式对象集合。每个RDD都被分为多个分区，这些分区运行在集群中的不同节点上。
创建RDD有2种方法：
- 读取一个外部数据集

  ~~~ scala
  lines = sc.textFile(filePath)
  ~~~

  linux中读取文件需要加上file:///前缀；windows中使用实际路径

- 在驱动器程序里分发驱动器程序中的对象集合（比如list和set）

  ~~~scala
  val lines = sc.parallelize(List("pandas", "numpy"))
  ~~~

## RDD算子

RDD支持两种类型的操作：转化操作（transformation）和行动操作（action）。

转化操作会由一个RDD生成一个新的RDD。行动操作会对RDD计算出一个结果，并把结果返回到驱动器程序中，或把结果存储到外部存储系统中。

转化操作和行动操作的区别在于Spark计算RDD的方式不同。虽然可以在任何时候定义新的RDD，但Spark只会惰性计算这些RDD。

默认情况下，Spark的RDD会造每次对它们进行行动操作时重新计算。如果想在多个行动操作中重用一个RDD，可以使用RDD.persist()让Spark把这个RDD缓存下来。
